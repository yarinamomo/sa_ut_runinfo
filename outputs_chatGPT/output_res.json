{
    "buggy": [
        {
            "ut10_tflin.py": {
                "error_joined": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] The placeholder X is defined with a shape of [n_input] which is a 1D array, but it should be a 2D array to match the shape of train_X which is a 2D array. The correct code should be X = tf.placeholder(tf.float32, [None, n_input]).",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] The placeholder Y is defined without a shape, but it should be a 1D array to match the shape of train_Y which is a 1D array. The correct code should be Y = tf.placeholder(tf.float32, [None]).",
                    "[error]: [25: W = tf.Variable(tf.zeros([6]), name=\"weight\")] The weight variable W is defined with a fixed shape of [6], but it should match the number of features in the input data. The correct code should be W = tf.Variable(tf.zeros([n_input]), name=\"weight\").",
                    "[error]: [27: activation = tf.add(tf.multiply(X, W), b)] The operation tf.multiply(X, W) is not valid because the shapes of X and W do not match. X is a 2D tensor and W is a 1D tensor. The correct operation should be tf.matmul(X, W)."
                ],
                "error_unioned": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] REASON: The placeholder X is defined with shape [n_input] which is a 1D array, but it should be a 2D array to match the shape of train_X which is a 2D array. The correct definition should be X = tf.placeholder(tf.float32, [None, n_input]).",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] REASON: The placeholder Y is defined without a shape, but it should be a 1D array to match the shape of train_Y. The correct definition should be Y = tf.placeholder(tf.float32, [None]).",
                    "[error]: [25: W = tf.Variable(tf.zeros([6]), name=\"weight\")] REASON: The weight variable W is defined with shape [6], but it should match the number of features in the input data. The correct definition should be W = tf.Variable(tf.zeros([n_input]), name=\"weight\").",
                    "[error]: [27: activation = tf.add(tf.multiply(X, W), b)] REASON: The operation tf.multiply(X, W) is not valid because the shapes of X and W do not match. The correct operation should be tf.matmul(X, W).",
                    "[error]: [37: \"{:.9f}\".format(sess.run(cost, feed_dict={X: train_X, Y: train_Y}))] REASON: The feed_dict is not valid because the shapes of X and train_X, and Y and train_Y do not match. The correct feed_dict should be {X: train_X, Y: train_Y.reshape(-1,1)}.",
                    "[error]: [28: cost = tf.reduce_sum(tf.pow(activation - Y, 2)) / (2 * n_samples)] The shapes of activation and Y are not compatible for subtraction. activation is a 2D array with shape [None, n_input] and Y is a 1D array with shape [None]. The shapes should be compatible for element-wise subtraction.",
                    "[error]: [43: training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})] REASON: The feed_dict is not valid because the shapes of X and train_X, and Y and train_Y do not match. The correct feed_dict should be {X: train_X, Y: train_Y.reshape(-1,1)}.",
                    "[error]: [47: testing_cost = sess.run(tf.reduce_sum(tf.pow(activation - Y, 2)) / (2 * test_X.shape[0]), feed_dict={X: test_X, Y: test_Y})] REASON: The feed_dict is not valid because the shapes of X and test_X, and Y and test_Y do not match. The correct feed_dict should be {X: test_X, Y: test_Y.reshape(-1,1)}."
                ],
                "error_majority": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] The placeholder X is defined with a shape of [n_input] which is a 1D array, but it should be a 2D array to match the shape of train_X which is a 2D array. The correct code should be X = tf.placeholder(tf.float32, [None, n_input]).",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] The placeholder Y is defined without a shape, but it should be a 1D array to match the shape of train_Y which is a 1D array. The correct code should be Y = tf.placeholder(tf.float32, [None]).",
                    "[error]: [25: W = tf.Variable(tf.zeros([6]), name=\"weight\")] The weight variable W is defined with a fixed shape of [6], but it should match the number of features in the input data. The correct code should be W = tf.Variable(tf.zeros([n_input]), name=\"weight\").",
                    "[error]: [27: activation = tf.add(tf.multiply(X, W), b)] The multiplication operation tf.multiply(X, W) is element-wise, but in this context, a matrix multiplication is needed. The correct code should be activation = tf.add(tf.matmul(X, W), b)."
                ]
            }
        },
        {
            "ut11_image.py": {
                "error": [
                    "[error]: [14: print(sess.run(X, feed_dict={X: x_expended_trans}))] The shape of the placeholder X is [None, 250, 250, 3] but the shape of the fed data x_expended_trans is [1, 3, 250, 250]. The shapes do not match."
                ]
            }
        },
        {
            "ut12_mnist.py": {
                "error": []
            }
        },
        {
            "ut13_linear.py": {
                "error": [
                    "[error]: [line 24] corrects = tf.equal(tf.argmax(Y, 1), tf.argmax(Yhat1, 1)) REASON: tf.argmax(Y, 1) and tf.argmax(Yhat1, 1) are used to find the maximum value index in the tensor along the axis 1. But Y and Yhat1 are both 2D tensors with shape [4, 1]. The axis 1 in both tensors only has one element, so it's meaningless to find the maximum value index along this axis. The correct axis should be 0."
                ]
            }
        },
        {
            "ut15_fitting.py": {
                "error": []
            }
        },
        {
            "ut1_mnist.py": {
                "error": []
            }
        },
        {
            "ut2_multiplication.py": {
                "error": [
                    "[error]: [14: p = tf.matmul(A_tf, B_tf)] The shapes of A_tf and B_tf are not compatible for matrix multiplication. A_tf has shape (M, h) and B_tf has shape (h, N, s). The tf.matmul operation expects the last dimension of the first input (A_tf) to match the second-to-last dimension of the second input (B_tf), but here h != N."
                ]
            }
        },
        {
            "ut3_image_set_shape.py": {
                "error": [
                    "[error]: [7: y.set_shape([478, 717, 3])] The shape of y is set to [478, 717, 3] which does not match the shape of x which is [1028178]. The shapes must match because y is created as an identity of x.",
                    "[error]: [13: Y = sess.run(y, feed_dict={x: X})] The tensor 'x' is fed with a numpy array 'X' of shape [1028178], which is compatible with its defined shape. However, 'y' is expected to have a shape of [478, 717, 3] but it is actually [1028178] because of the identity operation from 'x'. This will cause a shape mismatch error."
                ]
            }
        },
        {
            "ut4_experiment.py": {
                "error_joined": [],
                "error_unioned": [
                    "[error]: [59: y: test_labels, keep_prob: 1.0] REASON: The shape of 'test_labels' is not correct. It should be one-hot encoded but it is not. The 'test_labels' is generated by [random.randint(0, 9) for _ in range(length)] which will give a list of integers, but the expected input for 'y' placeholder is a one-hot encoded vector for each label."
                ],
                "error_majority": []
            }
        },
        {
            "ut5_mnist.py": {
                "error_joined": [
                    "[error]: [y = tf.placeholder(\"float\", [None, n_classes])] The shape of the placeholder y is defined as [None, n_classes] which means it expects a 2D tensor. However, the labels from mnist are loaded as one_hot=False which means they are not one-hot encoded and are 1D. The shape of y should be [None,] to match the shape of the labels."
                ],
                "error_unioned": [
                    "[error]: [y = tf.placeholder(\"float\", [None, n_classes])] The shape of the placeholder y is defined as [None, n_classes] which means it expects a 2D tensor. However, the labels from mnist are loaded as one_hot=False which means they are not one-hot encoded and are 1D. The shape of y should be [None,] to match the shape of the labels.",
                    "[error]: [sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))] The shape of test_label is not matching with the placeholder y. The test_label is a 1D tensor but y is expecting a 2D tensor."
                ],
                "error_majority": [
                    "[error]: [y = tf.placeholder(\"float\", [None, n_classes])] The shape of the placeholder y is defined as [None, n_classes] which means it expects a 2D tensor. However, the labels from mnist are loaded as one_hot=False which means they are not one-hot encoded and are 1D. The shape of y should be [None,] to match the shape of the labels.",
                    "[error]: [sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})] The shape of batch_y is not matching with the placeholder y. The batch_y is a 1D tensor but y is expecting a 2D tensor.",
                    "[error]: [print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict={x: test_data, y: test_label}))] The shape of test_label is not matching with the placeholder y. The test_label is a 1D tensor but y is expecting a 2D tensor."
                ]
            }
        },
        {
            "ut6_word_representation.py": {
                "error": [
                    "[error]: [return tf.matmul(layer_2, weights['out']) + biases['out']] The output of the second layer (layer_2) has a shape of [None, o2] and weights['out'] has a shape of [o2, 1]. The result of the matrix multiplication will have a shape of [None, 1] which does not match with the shape of the labels y which is [None, n_classes]. The shapes should match for the softmax_cross_entropy_with_logits function to work properly."
                ]
            }
        },
        {
            "ut7_playing.py": {
                "error_joined": [],
                "error_unioned": [
                    "error: 14: self.w = tf.Variable(normal_dist, name='weights') REASON: The shapes of the weights and the input data are not known at the time of the variable initialization. The shapes are determined dynamically during the execution of the graph. Therefore, the shape of the weights cannot be determined during the initialization of the variable."
                ],
                "error_majority": []
            }
        },
        {
            "ut8_multiply.py": {
                "error": [
                    "[error]: [7: l1 = tf.matmul(T1, x)] The shapes of T1 and x are not compatible for matrix multiplication. tf.matmul expects the last dimension of the first input (T1) to be the same as the second to last dimension of the second input (x). Here, T1 has shape [2, 2] and x has shape [2], so the operation is not valid."
                ]
            }
        },
        {
            "ut9_neural.py": {
                "error": [
                    "[error]: [13: y = tf.placeholder(\"float\")] The placeholder 'y' is missing a shape. It should match the shape of the labels. In this case, it should be [None, n_data]."
                ]
            }
        }
    ],
    "buggy_runinfo": [
        {
            "ut10_tflin_runinfo.py": {
                "error_joined": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] The placeholder X is defined with shape [n_input] which is a 1D array, but later in the code it is fed with 2D array train_X and test_X. The shape should be [None, n_input] to match the shape of train_X and test_X.",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] The placeholder Y is defined with no shape, but later in the code it is fed with 1D array train_Y and test_Y. The shape should be [None] to match the shape of train_Y and test_Y."
                ],
                "error_unioned": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] The placeholder X is defined with shape [n_input] which is a 1D array, but later in the code it is fed with 2D array train_X and test_X. The shape should be [None, n_input] to match the shape of train_X and test_X.",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] The placeholder Y is defined with no shape, but later in the code it is fed with 1D array train_Y and test_Y. The shape should be [None] to match the shape of train_Y and test_Y.",
                    "[error]: [25: W = tf.Variable(tf.zeros([6]), name=\"weight\")] The weight W is defined with shape [6] which is a 1D array, but it should be [n_input] to match the shape of input X.",
                    "[error]: [26: b = tf.Variable(tf.zeros([1]), name=\"bias\")] The bias b is defined with shape [1] which is a 1D array, but it should be a scalar to match the addition with the result of tf.multiply(X, W) in the activation function. The shape should be [].",
                    "[error]: [35: sess.run(optimizer, feed_dict={X: x, Y: y})] In the feed_dict, X is expected to be a 2D array and Y is expected to be a 1D array. However, x and y are scalar values as they are elements of train_X and train_Y respectively. This line should be replaced with \"sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\".",
                    "[error]: [37: \"cost=\", \"{:.9f}\".format(sess.run(cost, feed_dict={X: train_X, Y: train_Y}))] The cost operation expects X and Y to be 2D and 1D arrays respectively. However, train_X and train_Y are 2D and 1D arrays respectively. This line is correct.",
                    "[error]: [47: feed_dict={X: test_X, Y: test_Y})] The feed_dict expects X and Y to be 2D and 1D arrays respectively. However, test_X and test_Y are 2D and 1D arrays respectively. This line is correct."
                ],
                "error_majority": [
                    "[error]: [23: X = tf.placeholder(tf.float32, [n_input])] The placeholder X is defined with shape [n_input] which is a 1D array, but later in the code it is fed with 2D array train_X and test_X.",
                    "[error]: [24: Y = tf.placeholder(tf.float32)] The placeholder Y is defined with shape [] which is a scalar, but later in the code it is fed with 1D array train_Y and test_Y.",
                    "[error]: [25: W = tf.Variable(tf.zeros([6]), name=\"weight\")] The weight W is defined with shape [6] which is a 1D array, but it should be a 2D array [n_input, 1] to match the shape of X when performing tf.multiply(X, W)."
                ]
            }
        },
        {
            "ut11_image_runinfo.py": {
                "error": [
                    "[error]: [19: print(sess.run(X, feed_dict={X: x_expended_trans}))] The placeholder X expects a tensor of shape [None, 250, 250, 3] but x_expended_trans is of shape [1, 3, 250, 250]."
                ]
            }
        },
        {
            "ut12_mnist_runinfo.py": {
                "error": []
            }
        },
        {
            "ut13_linear_runinfo.py": {
                "error": [
                    "[error]: [37: corrects = tf.equal(tf.argmax(Y, 1), tf.argmax(Yhat1, 1))] The tf.argmax function is used incorrectly. It is used to find the index of the maximum value across dimensions of a tensor. However, in this case, Y and Yhat1 are both 2D tensors with shape [4, 1]. The maximum value index across the second dimension (1) will always be 0 because there is only one column. This operation does not make sense for tensors of this shape."
                ]
            }
        },
        {
            "ut15_fitting_runinfo.py": {
                "error": []
            }
        },
        {
            "ut1_mnist_runinfo.py": {
                "error_joined": [],
                "error_unioned": [
                    "error: [LINENUMBER: h_conv1 = tf.placeholder(tf.float32, [None, 24, 24, 32])] The shape of h_conv1 is defined as [None, 24, 24, 32] but it should be [None, 28, 28, 32] because the input image is of size 28x28 and we are using 32 filters.",
                    "error: [LINENUMBER: h_conv2 = tf.placeholder(tf.float32, [None, 8, 8, 64])] The shape of h_conv2 is defined as [None, 8, 8, 64] but it should be [None, 14, 14, 64] because the input to the second convolutional layer is of size 14x14 and we are using 64 filters.",
                    "error: [LINENUMBER: h_pool1 = tf.placeholder(tf.float32, [None, 12, 12, 32])] The shape of h_pool1 is defined as [None, 12, 12, 32] but it should be [None, 14, 14, 32] because the output of the first max pooling layer is of size 14x14 and we are using 32 filters.",
                    "error: [LINENUMBER: h_pool2 = tf.placeholder(tf.float32, [None, 4, 4, 64])] The shape of h_pool2 is defined as [None, 4, 4, 64] but it should be [None, 7, 7, 64] because the output of the second max pooling layer is of size 7x7 and we are using 64 filters.",
                    "error: [LINENUMBER: y_conv = tf.placeholder(tf.float32, [None, 10])] The shape of y_conv is defined as [None, 10] but it should be [None, 1] because the output of the softmax function is a scalar probability for each class."
                ],
                "error_majority": []
            }
        },
        {
            "ut2_multiplication_runinfo.py": {
                "error": [
                    "[error]: [23: p = tf.matmul(A_tf, B_tf)] The shapes of A_tf and B_tf are not compatible for matrix multiplication. tf.matmul expects the last dimension of the first input tensor (A_tf) to be the same as the second to last dimension of the second input tensor (B_tf). Here, A_tf has shape (5, 2) and B_tf has shape (2, 2, 3). The last dimension of A_tf is 2, but the second to last dimension of B_tf is also 2, not matching the required condition."
                ]
            }
        },
        {
            "ut3_image_set_shape_runinfo.py": {
                "error": [
                    "[error]: [9: y.set_shape([478, 717, 3])] The tensor 'y' is defined as the identity of 'x', which means it has the same shape as 'x'. However, the shape of 'y' is then set to [478, 717, 3], which is a 3D shape. This is inconsistent with the 1D shape of 'x', and will cause a shape mismatch error."
                ]
            }
        },
        {
            "ut4_experiment_runinfo.py": {
                "error_joined": [],
                "error_unioned": [
                    "error: 125: train_accuracy = accuracy.eval(feed_dict={x: image_batch, y: label_batch, keep_prob: 1.0}) REASON: The placeholder 'y' expects a one-hot encoded vector of size [None, 10] but 'label_batch' is a list of integers. The shapes do not match.",
                    "error: 127: train_step.run(feed_dict={x: image_batch, y: label_batch, keep_prob: 0.5}) REASON: The placeholder 'y' expects a one-hot encoded vector of size [None, 10] but 'label_batch' is a list of integers. The shapes do not match.",
                    "error: 130: accuracy.eval(feed_dict={x: test_images, y: test_labels, keep_prob: 1.0}) REASON: The placeholder 'y' expects a one-hot encoded vector of size [None, 10] but 'test_labels' is a list of integers. The shapes do not match."
                ],
                "error_majority": []
            }
        },
        {
            "ut5_mnist_runinfo.py": {
                "error": [
                    "error: [LINE: y = tf.placeholder(\"float\", [None, n_classes])] REASON: The shape of the placeholder 'y' is defined as [None, n_classes] which is [None, 10]. But the labels are read as one_hot=False which means they are not one-hot encoded and their shape is [None,]. The shape of the placeholder 'y' should be [None,].",
                    "error: [LINE 47: sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})] REASON: The shape of batch_y does not match the expected shape. The placeholder y expects a one-hot encoded vector of size 10 for each example, but batch_y from mnist.train.next_batch(params['batch_size']) returns a single integer label for each example."
                ]
            }
        },
        {
            "ut6_word_representation_runinfo.py": {
                "error": [
                    "error: [23: return tf.matmul(layer_2, weights['out']) + biases['out']] The output of the second layer (layer_2) has a shape of [None, o2] and weights['out'] has a shape of [o2, 1]. The result of the matrix multiplication will have a shape of [None, 1]. However, biases['out'] has a shape of [1] which does not match with the result of the matrix multiplication. The shapes should be compatible for the addition operation."
                ]
            }
        },
        {
            "ut7_playing_runinfo.py": {
                "error_joined": [],
                "error_unioned": [
                    "error: 14: self.w = tf.Variable(normal_dist, name='weights') REASON: The shapes of the weights and the input data are not known at the time of the variable initialization. The shapes are determined dynamically during the execution of the graph. Therefore, the shape of the weights cannot be determined during the initialization of the variable."
                ],
                "error_majority": []
            }
        },
        {
            "ut8_multiply_runinfo.py": {
                "error": [
                    "[error]: [7: l1 = tf.matmul(T1, x)] The shapes of T1 and x are not compatible for matrix multiplication. tf.matmul expects the last dimension of the first input (T1) and the second-to-last dimension of the second input (x) to be the same. Here, T1 has shape [2, 2] and x has shape [2], so their inner dimensions do not match."
                ]
            }
        },
        {
            "ut9_neural_runinfo.py": {
                "error": [
                    "[error]: [19: y = tf.placeholder(\"float\")] The placeholder 'y' should have a shape specified. In this case, it should match the shape of the labels.",
                    "[error]: [27: cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))] The labels in softmax_cross_entropy_with_logits should have the same shape as logits. Here, 'y' is a placeholder with no shape specified, which may cause a shape mismatch error."
                ]
            }
        }
    ],
    "fix": [
        {
            "ut10_tflin_fix.py": {
                "error": [
                    "[error]: [23: W = tf.Variable(tf.zeros([6, 1]), name=\"weight\")] The shape of the weight matrix W should be [n_input, 1] not [6, 1]. The number of rows in the weight matrix should be equal to the number of features (n_input) in the input data."
                ]
            }
        },
        {
            "ut11_image_fix.py": {
                "error": []
            }
        },
        {
            "ut12_mnist_fix.py": {
                "error": []
            }
        },
        {
            "ut13_linear_fix.py": {
                "error": []
            }
        },
        {
            "ut15_fitting_fix.py": {
                "error": []
            }
        },
        {
            "ut1_mnist_fix.py": {
                "error": []
            }
        },
        {
            "ut2_multiplication_fix.py": {
                "error": []
            }
        },
        {
            "ut3_image_set_shape_fix.py": {
                "error": [
                    "[error]: y = tf.reshape(y, [478, 717, 3]) REASON: The reshape function is trying to reshape 'y' into a shape of [478, 717, 3] which is not compatible with the shape of 'y' ([1028178]). The total number of elements in the reshaped tensor must be the same as the original tensor. But 478*717*3 = 1028178, so there is no shape mismatch here."
                ]
            }
        },
        {
            "ut4_experiment_fix.py": {
                "error": []
            }
        },
        {
            "ut5_mnist_fix.py": {
                "error": []
            }
        },
        {
            "ut6_word_representation_fix.py": {
                "error_joined": [
                    "[error]: [return tf.matmul(layer_2, weights['out']) + biases['out']] REASON: The output of the multilayer_perceptron function has a shape of [None, 1] due to the weights['out'] shape of [o2, 1]. However, this is being used as the logits in tf.nn.softmax_cross_entropy_with_logits, where it is expected to match the shape of labels, which is [None, n_classes] or [None, 10]. The shapes [None, 1] and [None, 10] are incompatible."
                ],
                "error_unioned": [
                    "[error]: [weights = {\"out\": tf.random_uniform([o2, 1]), \"h1\": tf.random_uniform([embedding_size, o1]),",
                    "[error]: [return tf.matmul(layer_2, weights['out']) + biases['out']] The output layer biases should have a shape of [n_classes] instead of [1] because the output layer should have the same number of neurons as the number of classes.",
                    "[error]: [y = tf.placeholder(tf.float32, [None, n_classes])] REASON: The shape of the placeholder 'y' should match the shape of the output of the network. Since the output of the network is of shape [None, 1], 'y' should also have the same shape."
                ],
                "error_majority": [
                    "[error]: [return tf.matmul(layer_2, weights['out']) + biases['out']] REASON: The output of the multilayer_perceptron function has a shape of [None, 1] due to the weights['out'] shape of [o2, 1]. However, this is being used as the logits in tf.nn.softmax_cross_entropy_with_logits, where it is expected to match the shape of labels, which is [None, n_classes] or [None, 10]. The shapes [None, 1] and [None, 10] are incompatible."
                ]
            }
        },
        {
            "ut7_playing_fix.py": {
                "error": []
            }
        },
        {
            "ut8_multiply_fix.py": {
                "error": []
            }
        },
        {
            "ut9_neural_fix.py": {
                "error": [
                    "[error]: [16: y_trans = tf.transpose(y, [1, 0])] REASON: The 'y' placeholder is defined with a rank of 1 (shape=[None]), but the transpose operation is trying to transpose it as if it had a rank of 2. The transpose operation is expecting a tensor of rank 2 but got a tensor of rank 1."
                ]
            }
        }
    ],
    "fix_runinfo": [
        {
            "ut10_tflin_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut11_image_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut12_mnist_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut13_linear_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut15_fitting_fix_runinfo.py": {
                "error": [
                    "Error: [19: sess.run(train_step)] The placeholders x, y, and y_ are not being fed any values during the session run."
                ]
            }
        },
        {
            "ut1_mnist_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut2_multiplication_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut3_image_set_shape_fix_runinfo.py": {
                "error": [
                    "[error]: [9: y = tf.reshape(y, [478, 717, 3])] The reshape operation is trying to reshape the tensor of shape (1028178,) into a tensor of shape (478, 717, 3) which is not possible because 478*717*3 = 1028196 != 1028178. The total size of the new shape must be the same as the total size of the original shape."
                ]
            }
        },
        {
            "ut4_experiment_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut5_mnist_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut6_word_representation_fix_runinfo.py": {
                "error": [
                    "Error: [19: return tf.matmul(layer_2, weights['out']) + biases['out']] The shape of weights['out'] is [o2, 1] but it should be [o2, n_classes] to match the shape of biases['out'] which is [n_classes]."
                ]
            }
        },
        {
            "ut7_playing_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut8_multiply_fix_runinfo.py": {
                "error": []
            }
        },
        {
            "ut9_neural_fix_runinfo.py": {
                "error": [
                    "[error]: [y_trans = tf.transpose(y, [1, 0])] REASON: The transpose operation is not applicable to 'y' as it is a 1D tensor. The transpose operation requires a tensor of rank 2 or more."
                ]
            }
        }
    ]
}