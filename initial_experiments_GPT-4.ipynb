{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f50335",
   "metadata": {},
   "source": [
    "## Run GPT-4 as a static analyzer\n",
    "\n",
    "After carefully tuning the prompts, the prompt is formulated into:\n",
    "\n",
    "    You will be given a piece of Python code, many of which use the TensorFlow library. Your job is to find shape-related errors if there are any. Only focus on errors that occur when the used shape does not match the expected shape in an operator or function. Ignore the errors related to redefined or fixed shape definitions. Generate outputs according to the templates: \"No shape mismatch found.\" if no shape errors found, or \"[error]: [LINENUMBER: LINEOFCODE] REASON\" if any shape errors are found, and make sure to provide reasons.\n",
    "\n",
    "Note: you should have setup own API key to run GPT-4 locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fb8ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sa_by_chatGPT\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53ddd8",
   "metadata": {},
   "source": [
    "remove comments systematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0596d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove comments in the code (prevent chatGPT takes short cuts)\n",
    "\n",
    "# py_paths_all = sa_by_chatGPT.get_py_paths('')\n",
    "# for key, py_paths in py_paths_all.items():\n",
    "#     tar_folder = \"data4chatGPT/tf_fix_py\"\n",
    "#     if 'buggy' in key:\n",
    "#         tar_folder = \"data4chatGPT/tf_bugs_py\"\n",
    "#     for py_path in py_paths:\n",
    "#         sa_by_chatGPT.remove_comments_and_docstrings_python(py_path, tar_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5d8e42",
   "metadata": {},
   "source": [
    "run with single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_by_chatGPT.chatGPT_py_file('data4chatGPT\\\\tf_bugs_py\\\\ut4_experiment_runinfo.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04ece5c",
   "metadata": {},
   "source": [
    "run all the data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781f7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on Pythia dataset\n",
    "# buggy and fix version is run separately to avoid long waiting time\n",
    "ress_chatGPT = {}\n",
    "py_paths_all = sa_by_chatGPT.get_py_paths('data4chatGPT')\n",
    "for key, py_paths in py_paths_all.items():\n",
    "    #if 'fix' not in key: # 'buggy'  #only the buggy (+runinfo) version\n",
    "    #    continue\n",
    "    for py_path in py_paths:\n",
    "        res = sa_by_chatGPT.chatGPT_py_file(py_path)\n",
    "        if key in ress_chatGPT:\n",
    "            ress_chatGPT[key].append({os.path.basename(py_path):res})\n",
    "        else:\n",
    "            ress_chatGPT[key]=[{os.path.basename(py_path):res}]\n",
    "#ress_chatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690953de",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "save the results from GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "  \n",
    "# save the output data\n",
    "def extract_errors(data):\n",
    "    result = {}\n",
    "    for category, entries in data.items():\n",
    "        result[category] = []\n",
    "        for entry in entries:\n",
    "            for file_name, message in entry.items():\n",
    "                errors = message.strip('\"').split('\\n')\n",
    "                errors = [error.strip().strip('\"') for error in errors if '[error]' in error.lower() or 'error:' in error.lower()]\n",
    "\n",
    "                result[category].append({\n",
    "                    file_name: {\n",
    "                        'error_count': len(errors),\n",
    "                        'error': errors\n",
    "                    }\n",
    "                })\n",
    "    return result\n",
    "\n",
    "tmp = extract_errors(ress_chatGPT)\n",
    "\n",
    "with open('output_chatGPT/output_1.json', 'w') as json_file:\n",
    "    json.dump(tmp, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab781e0e",
   "metadata": {},
   "source": [
    "Upon processing the \\gpt{} outputs, certain errors were identified with seemingly unreasonable justifications. For instance, in the \\ut-3 fixed version with run-time information, \\gpt{} yielded the following output:\n",
    "\n",
    "    [error]: [9: y = tf.reshape(y, [478, 717, 3])] The reshape operation is trying to reshape the tensor of shape (1028178,) into a tensor of shape (478, 717, 3) which is not possible because 478*717*3 = 1028196 != 1028178. The total size of the new shape must be the same as the total size of the original shape.\n",
    "\n",
    "It claims 478*717*3 = 1028196, whereas the correct calculation is 478*717*3 = 1028178, rendering this reported error logically incorrect. Instances like this were not considered valid errors, occurring twice in total, both for the \\ut-3 fixed version, with and without run-time information.\n",
    "\n",
    "The saved raw outputs can be found in folder: ut_dataset_runinfo\\output_chatGPT\n",
    "\n",
    "The processed results for GPT-4 can be found: ut_dataset_runinfo\\output_chatGPT\\results_chatGPT.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ee5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52bd6331",
   "metadata": {},
   "source": [
    "Appendix: test a simple case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c880311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# file_path = 'data4chatGPT\\\\simple_test_for_chatGPT.py'\n",
    "# res = sa_by_chatGPT.chatGPT_py_file(file_path)\n",
    "# print(os.path.basename(file_path) + '\\n' + res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83276f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove comments from the simple case\n",
    "# sa_by_chatGPT.remove_comments_and_docstrings_python('data4chatGPT\\\\simple_test_for_chatGPT.py', 'data4chatGPT/tf_bugs_py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5009e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the simple case without comments\n",
    "# print(sa_by_chatGPT.chatGPT_py_file('data4chatGPT\\\\tf_bugs_py\\\\simple_test_for_chatGPT.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f6a05e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
